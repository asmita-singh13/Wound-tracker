{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eaec10a-dca1-44b3-a969-4eed0a4b7f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # type: ignore\n",
    "import cv2 # type: ignore\n",
    "from PIL import Image # type: ignore\n",
    "from datetime import datetime \n",
    "\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import glob\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32b1ea95-b18f-42aa-ac78-bd9909e33e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DeepLabV3+\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, UpSampling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "\"\"\" Atrous Spatial Pyramid Pooling \"\"\"\n",
    "def ASPP(inputs):\n",
    "    shape = inputs.shape\n",
    "\n",
    "    y_pool = AveragePooling2D(pool_size=(shape[1], shape[2]), name='average_pooling')(inputs)\n",
    "    y_pool = Conv2D(filters=256, kernel_size=1, padding='same', use_bias=False)(y_pool)\n",
    "    y_pool = BatchNormalization(name=f'bn_1')(y_pool)\n",
    "    y_pool = Activation('relu', name=f'relu_1')(y_pool)\n",
    "    y_pool = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y_pool)\n",
    "\n",
    "    y_1 = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(inputs)\n",
    "    y_1 = BatchNormalization()(y_1)\n",
    "    y_1 = Activation('relu')(y_1)\n",
    "\n",
    "    y_6 = Conv2D(filters=256, kernel_size=3, dilation_rate=6, padding='same', use_bias=False)(inputs)\n",
    "    y_6 = BatchNormalization()(y_6)\n",
    "    y_6 = Activation('relu')(y_6)\n",
    "\n",
    "    y_12 = Conv2D(filters=256, kernel_size=3, dilation_rate=12, padding='same', use_bias=False)(inputs)\n",
    "    y_12 = BatchNormalization()(y_12)\n",
    "    y_12 = Activation('relu')(y_12)\n",
    "\n",
    "    y_18 = Conv2D(filters=256, kernel_size=3, dilation_rate=18, padding='same', use_bias=False)(inputs)\n",
    "    y_18 = BatchNormalization()(y_18)\n",
    "    y_18 = Activation('relu')(y_18)\n",
    "\n",
    "    y = Concatenate()([y_pool, y_1, y_6, y_12, y_18])\n",
    "\n",
    "    y = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    return y\n",
    "\n",
    "def DeepLabV3Plus(shape):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    inputs = Input(shape)\n",
    "\n",
    "    \"\"\" Pre-trained ResNet101 \"\"\"\n",
    "    # base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "    # base_model.summary()\n",
    "    \"\"\" Pre-trained ResNet50 Output \"\"\"\n",
    "    # image_features = base_model.get_layer('block14_sepconv1_act').output\n",
    "    # image_features = base_model.get_layer('conv4_block23_2_relu').output\n",
    "    # image_features = base_model.get_layer('out_relu').output\n",
    "    image_features = base_model.get_layer('conv4_block6_out').output\n",
    "    x_a = ASPP(image_features)\n",
    "    x_a = UpSampling2D((4, 4), interpolation=\"bilinear\")(x_a)\n",
    "\n",
    "    \"\"\" Get low-level features \"\"\"\n",
    "    # x_b = base_model.get_layer('block4_sepconv2').output\n",
    "    x_b = base_model.get_layer('conv2_block2_out').output\n",
    "    x_b = Conv2D(filters=48, kernel_size=1, padding='same', use_bias=False)(x_b)\n",
    "    x_b = BatchNormalization()(x_b)\n",
    "    x_b = Activation('relu')(x_b)\n",
    "\n",
    "    x = Concatenate()([x_a, x_b])\n",
    "\n",
    "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu',use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = UpSampling2D((4, 4), interpolation=\"bilinear\")(x)\n",
    "\n",
    "    \"\"\" Outputs \"\"\"\n",
    "    x = Conv2D(1, (1, 1), name='output_layer')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# check =  DeepLabV3Plus((224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3af32ef-5019-427f-bbc0-fb255695b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "train_images_path = \"./medtec/data_wound_seg/train_images\"\n",
    "train_labels_path = \"./medtec/data_wound_seg/train_masks\"\n",
    "test_images_path = \"./medtec/data_wound_seg/test_images\"\n",
    "test_labels_path = \"./medtec/data_wound_seg/test_masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c965fbee-3c8e-4471-90df-5f6087a8b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 4\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a9f94e8-6bcd-41bb-bd92-dbf1065f5e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(images_path, labels_path, img_size=(224, 224)):\n",
    "    # List all image files in the directories\n",
    "    image_files = sorted([f for f in os.listdir(images_path) if os.path.isfile(os.path.join(images_path, f))])\n",
    "    label_files = sorted([f for f in os.listdir(labels_path) if os.path.isfile(os.path.join(labels_path, f))])\n",
    "\n",
    "    # Initialize lists to hold image and label data\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Loop over image files\n",
    "    for img_file, label_file in zip(image_files, label_files):\n",
    "        # Load the image and label\n",
    "        img = load_img(os.path.join(images_path, img_file), target_size=img_size)\n",
    "        label = load_img(os.path.join(labels_path, label_file), target_size=img_size, color_mode='grayscale')\n",
    "\n",
    "        # Convert them to numpy arrays\n",
    "        img_array = img_to_array(img) / 255.0  # Normalize images to range [0, 1]\n",
    "        label_array = img_to_array(label) / 255.0  # Normalize labels (assuming binary segmentation)\n",
    "\n",
    "        # Append to the lists\n",
    "        images.append(img_array)\n",
    "        labels.append(label_array)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    print(\"images: \", images.shape)\n",
    "    labels = np.array(labels)\n",
    "    print(\"labels: \", labels.shape)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5aff17-8ea2-4cbb-af13-62bf06c3d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "train_images, train_labels = load_data(train_images_path, train_labels_path)\n",
    "test_images, test_labels = load_data(test_images_path, test_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a4cba8-574c-418d-aa50-b6f0ea8309e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_sample(image, label, idx=0):\n",
    "    # Plot the image and corresponding label side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    \n",
    "    # Plot the image\n",
    "    axes[0].imshow(image[idx])  # Show the image\n",
    "    axes[0].set_title(\"Image\")\n",
    "    axes[0].axis('off')  # Hide axis\n",
    "    \n",
    "    # Plot the label (ground truth)\n",
    "    axes[1].imshow(label[idx], cmap='gray')  # Show the label in grayscale\n",
    "    axes[1].set_title(\"Label\")\n",
    "    axes[1].axis('off')  # Hide axis\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the first sample from the training data\n",
    "visualize_sample(train_images, train_labels, idx=58)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f6ae4b-deee-44d1-ad18-a70fac860481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "\n",
    "model = DeepLabV3Plus((224,224,3))\n",
    "\n",
    "# Define a ModelCheckpoint callback to save the best weights\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    'mob_weights.h5',  # Path to save the best model weights\n",
    "    monitor='val_loss',  # Monitor validation loss to save best weights\n",
    "    save_best_only=True,  # Only save the best model based on validation loss\n",
    "    mode='min',  # Minimize validation loss\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss = keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels ,\n",
    "                    verbose=1,\n",
    "                    batch_size = 8,\n",
    "                    validation_data=(test_images, test_labels),\n",
    "                    shuffle=False,\n",
    "                    epochs=50,\n",
    "                    callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf2b38-71da-4f67-99b0-a0cb8455c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, you can plot the loss and accuracy curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the loss curve\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy curve (if accuracy metric is used)\n",
    "if 'accuracy' in history.history:\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa28ec21-2d81-4fad-8588-ce6ab45283f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"resnet50deeplabv3_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e15fc988-1a09-4cc9-97c0-0990d8ab9787",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_wound.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbb09e5f-d054-43b0-b54c-37b2f48ba2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"kermodel_wound.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f792ee7-e368-412d-baa4-ce187f84aa30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow GPU",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
